{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc63990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doctoq/Desktop/Dev/MADRL-Cooperative-Push-Env/venv/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.no_grad at 0x7f9e2ab910a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from src.utils.config import get_config\n",
    "from src.utils.utils import set_seeds, load_args, set_cuda_device\n",
    "from src.envs.make_env import make_env\n",
    "from src.lmc.lmc_context import LMC\n",
    "\n",
    "def create_cfg(args_file):\n",
    "    class Config:\n",
    "        pass\n",
    "    cfg = Config()\n",
    "    \n",
    "    with open(args_file) as f:\n",
    "        [next(f) for i in range(3)]\n",
    "        args = json.load(f)\n",
    "    args.pop(\"cuda_device\")\n",
    "    \n",
    "    for a in args:\n",
    "        setattr(cfg, a, args[a])\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "\n",
    "cfg = create_cfg(\"../../models/magym_PredPrey/FT_ShMloc_shap_reccommpol/run4/args.txt\")\n",
    "cfg.n_parallel_envs = 1\n",
    "\n",
    "# Create train environment\n",
    "envs, parser = make_env(cfg, cfg.n_parallel_envs)\n",
    "\n",
    "# Create model\n",
    "n_agents = envs.n_agents\n",
    "obs_space = envs.observation_space\n",
    "shared_obs_space = envs.shared_observation_space\n",
    "act_space = envs.action_space\n",
    "global_state_dim = envs.global_state_dim\n",
    "model = LMC(\n",
    "    cfg, \n",
    "    n_agents, \n",
    "    obs_space, \n",
    "    shared_obs_space, \n",
    "    act_space,\n",
    "    parser.vocab, \n",
    "    global_state_dim)\n",
    "\n",
    "# Load params\n",
    "model.load(\"../../models/magym_PredPrey/FT_ShMloc_shap_reccommpol/run4/model_ep.pt\")\n",
    "model.prep_rollout()\n",
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.], (27,), float32), Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.], (27,), float32), Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.], (27,), float32), Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.], (27,), float32)]\n"
     ]
    }
   ],
   "source": [
    "print(obs_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing perplexity of perfect sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_sent = [\n",
    "    [\"Prey\", \"Located\", \"South\"],\n",
    "    [\"Prey\", \"Located\", \"North\", \"Prey\", \"Located\", \"South\"],\n",
    "    [\"<SOS>\", \"<SOS>\"]\n",
    "]\n",
    "\n",
    "ll = model.lang_learner\n",
    "\n",
    "onehot_sent = ll.word_encoder.encode_batch(perf_sent)\n",
    "onehot_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros((1, 1, 16))\n",
    "last_tokens = torch.Tensor(ll.word_encoder.SOS_ENC).view(\n",
    "    1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.8816, -1.8924, -1.7783, -2.2814, -2.7779, -2.3432, -2.2925,\n",
      "          -2.5420, -2.5612, -2.2344]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[0.0560, 0.1507, 0.1689, 0.1021, 0.0622, 0.0960, 0.1010, 0.0787,\n",
      "          0.0772, 0.1071]]], grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output, hidden = ll.decoder.forward_step(last_tokens, hidden)\n",
    "print(output)\n",
    "print(output.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.exp().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.7681,  3.9997, 13.0349], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = ll.decoder\n",
    "n_layers = 1\n",
    "def compute_pp(enc_sent):\n",
    "    batch_size = len(enc_sent)\n",
    "    max_sent_len = max([len(s) for s in enc_sent])\n",
    "\n",
    "    hidden = torch.zeros((n_layers, batch_size, decoder.hidden_dim))\n",
    "    last_tokens = torch.Tensor(decoder.word_encoder.SOS_ENC).view(\n",
    "        1, 1, -1).repeat(1, batch_size, 1).to(decoder.device)\n",
    "\n",
    "    pnorm = torch.ones(batch_size)\n",
    "    for t_i in range(max_sent_len):\n",
    "        # RNN pass\n",
    "        outputs, hidden = decoder.forward_step(last_tokens, hidden)\n",
    "\n",
    "        # Compute PP\n",
    "        probs = outputs.exp().squeeze(0)\n",
    "        for s_i in range(batch_size):\n",
    "            len_s = enc_sent[s_i].size(0)\n",
    "            if t_i < len_s:\n",
    "                token_prob = (probs[s_i] * enc_sent[s_i][t_i]).sum(-1)\n",
    "                pnorm[s_i] *= (token_prob ** (1 / len_s))\n",
    "\n",
    "        # Do teacher forcing\n",
    "        last_tokens = torch.zeros_like(last_tokens).to(decoder.device)\n",
    "        for s_i in range(batch_size):\n",
    "            if t_i < enc_sent[s_i].size(0):\n",
    "                last_tokens[0, s_i] = enc_sent[s_i][t_i]\n",
    "\n",
    "    pnorm = 1 / pnorm\n",
    "\n",
    "    return pnorm\n",
    "\n",
    "compute_pp(onehot_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
