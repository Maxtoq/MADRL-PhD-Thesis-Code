{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14998a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import psi\n",
    "from math import log, exp\n",
    "\n",
    "def discrete_continuous_info(d, c, k=3, base=exp(1)):\n",
    "    \"\"\"\n",
    "    Estimates mutual information between a discrete vector 'd' and continuous vectors 'c'.\n",
    "    \n",
    "    Args:\n",
    "        d (np.ndarray): Discrete array of shape (1, N) or (N,)\n",
    "        c (np.ndarray): Continuous data of shape (M, N) where M is feature dim\n",
    "        k (int): Number of nearest neighbors\n",
    "        base (float): Logarithm base (default: natural log)\n",
    "    \n",
    "    Returns:\n",
    "        f (float): Estimated mutual information\n",
    "        V (np.ndarray): Volume estimates for each sample\n",
    "    \"\"\"\n",
    "    d = np.asarray(d)\n",
    "    c = np.asarray(c)\n",
    "\n",
    "    if d.ndim == 1:\n",
    "        d = d.reshape(1, -1)\n",
    "    if c.ndim == 1:\n",
    "        c = c.reshape(1, -1)\n",
    "\n",
    "    N = c.shape[1]\n",
    "    symbol_IDs = np.zeros(N, dtype=int)\n",
    "    first_symbol = []\n",
    "    c_split = []\n",
    "    cs_indices = []\n",
    "    num_d_symbols = 0\n",
    "\n",
    "    # Bin continuous data by discrete symbols\n",
    "    for i in range(N):\n",
    "        found = False\n",
    "        for j in range(num_d_symbols):\n",
    "            if d[:, i] == d[:, first_symbol[j]]:\n",
    "                symbol_IDs[i] = j\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            symbol_IDs[i] = num_d_symbols\n",
    "            first_symbol.append(i)\n",
    "            c_split.append([])\n",
    "            cs_indices.append([])\n",
    "            num_d_symbols += 1\n",
    "\n",
    "        c_split[symbol_IDs[i]].append(c[:, i])\n",
    "        cs_indices[symbol_IDs[i]].append(i)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    for i in range(num_d_symbols):\n",
    "        c_split[i] = np.column_stack(c_split[i])\n",
    "\n",
    "    m_tot = 0\n",
    "    av_psi_Nd = 0\n",
    "    V = np.zeros(N)\n",
    "    all_c_distances = np.zeros(N)\n",
    "    psi_ks = 0\n",
    "\n",
    "    for c_bin in range(num_d_symbols):\n",
    "        n_bin = c_split[c_bin].shape[1]\n",
    "        one_k = min(k, n_bin - 1)\n",
    "\n",
    "        if one_k > 0:\n",
    "            for pivot in range(n_bin):\n",
    "                # Compute distances within bin\n",
    "                c_pivot = c_split[c_bin][:, pivot]\n",
    "                c_distances = np.linalg.norm(c_split[c_bin] - c_pivot[:, None], axis=0)\n",
    "                sorted_distances = np.sort(c_distances)\n",
    "                eps_over_2 = sorted_distances[one_k + 1]  # skip pivot\n",
    "\n",
    "                # Count total points within volume\n",
    "                all_distances = np.linalg.norm(c - c_pivot[:, None], axis=0)\n",
    "                m = max(np.sum(all_distances <= eps_over_2) - 1, 0)\n",
    "\n",
    "                m_tot += psi(m)\n",
    "                V[cs_indices[c_bin][pivot]] = (2 * eps_over_2) ** d.shape[0]\n",
    "        else:\n",
    "            m_tot += psi(num_d_symbols * 2)\n",
    "\n",
    "        p_d = n_bin / N\n",
    "        av_psi_Nd += p_d * psi(p_d * N)\n",
    "        psi_ks += p_d * psi(max(one_k, 1))\n",
    "\n",
    "    f = (psi(N) - av_psi_Nd + psi_ks - m_tot / N) / log(base)\n",
    "    return f, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9f733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.special import digamma\n",
    "from math import log, exp\n",
    "\n",
    "def discrete_continuous_info_2(d, c, k=3, base=np.e):\n",
    "    \"\"\"\n",
    "    Estimates the mutual information between a discrete vector `d`\n",
    "    and a continuous matrix `c` using a nearest-neighbor approach.\n",
    "    \n",
    "    Parameters:\n",
    "    d (np.ndarray): 1D array of discrete labels (shape: [n_samples])\n",
    "    c (np.ndarray): 2D array of continuous data (shape: [n_features, n_samples])\n",
    "    k (int): number of nearest neighbors (default: 3)\n",
    "    base (float): log base for the mutual information (default: natural log)\n",
    "    \n",
    "    Returns:\n",
    "    f (float): estimated mutual information\n",
    "    V (np.ndarray): estimated local volume per point\n",
    "    \"\"\"\n",
    "    n_samples = c.shape[1]\n",
    "    symbol_IDs = np.zeros(n_samples, dtype=int)\n",
    "    c_split = {}\n",
    "    cs_indices = {}\n",
    "    unique_labels = []\n",
    "    num_d_symbols = 0\n",
    "\n",
    "    # Bin the data by discrete labels\n",
    "    for i in range(n_samples):\n",
    "        label = d[i]\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "            num_d_symbols += 1\n",
    "            c_split[label] = []\n",
    "            cs_indices[label] = []\n",
    "        c_split[label].append(c[:, i])\n",
    "        cs_indices[label].append(i)\n",
    "\n",
    "    for label in c_split:\n",
    "        c_split[label] = np.column_stack(c_split[label])  # Convert to numpy array\n",
    "\n",
    "    m_tot = 0\n",
    "    av_psi_Nd = 0\n",
    "    V = np.zeros(n_samples)\n",
    "    psi_ks = 0\n",
    "\n",
    "    for label in c_split:\n",
    "        group_c = c_split[label]\n",
    "        group_indices = cs_indices[label]\n",
    "        n_group = group_c.shape[1]\n",
    "        one_k = min(k, n_group - 1)\n",
    "\n",
    "        if one_k > 0:\n",
    "            for pivot in range(n_group):\n",
    "                pivot_vec = group_c[:, pivot].reshape(-1, 1)\n",
    "                diffs = group_c - pivot_vec\n",
    "                distances = np.linalg.norm(diffs, axis=0)\n",
    "                sorted_distances = np.sort(distances)\n",
    "                eps_over_2 = sorted_distances[one_k + 1]  # k-th neighbor (skip self)\n",
    "\n",
    "                # Count neighbors in all data within this radius\n",
    "                full_diffs = c - pivot_vec\n",
    "                all_distances = np.linalg.norm(full_diffs, axis=0)\n",
    "                m = max(np.sum(all_distances <= eps_over_2) - 1, 0)\n",
    "                m_tot += digamma(m + 1)  # +1 for numerical stability\n",
    "                V[group_indices[pivot]] = (2 * eps_over_2) ** c.shape[0]\n",
    "        else:\n",
    "            m_tot += digamma(num_d_symbols * 2)\n",
    "\n",
    "        p_d = n_group / n_samples\n",
    "        av_psi_Nd += p_d * digamma(n_group)\n",
    "        psi_ks += p_d * digamma(max(one_k, 1))\n",
    "\n",
    "    f = (digamma(n_samples) - av_psi_Nd + psi_ks - m_tot / n_samples) / log(base)\n",
    "    return f, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def compute_kmu(x, y, per_filter=True, avarage=True, n_neighbors=3):\n",
    "    \"\"\"Compute mutual information between continious and discrete variables\n",
    "    :parameter\n",
    "    x : ndarray, shape (batch_size, n_filters, height, width)\n",
    "         4d continious variable,\n",
    "    y : ndarray,  shape (batch_size, )\n",
    "        1d discrete variable\n",
    "    per_filter : bool,\n",
    "        Whether to calculate mu between each 3d filter and discrete variable, or full 4d tensor and discrete variable\n",
    "    avarage : bool,\n",
    "        In case of per_filter=True, average the result or not\n",
    "    n_neighbors: int,\n",
    "        Number of nearest neighbors to search for each point\n",
    "     :returns\n",
    "     kmu : float, or list of floats (depends on per_filter parameter),\n",
    "        Estimated mutual information\n",
    "     \"\"\"\n",
    "    if per_filter:\n",
    "        filters_count = x.shape[1]\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "        kmu = [mu_approximate(x[:, i, :], y, n_neighbors=n_neighbors) for i in range(filters_count)]\n",
    "    else:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        kmu = mu_approximate(x, y, n_neighbors=n_neighbors)\n",
    "\n",
    "    if avarage:\n",
    "        kmu = np.mean(kmu)\n",
    "\n",
    "    return kmu\n",
    "\n",
    "\n",
    "def nn_sklearn(x, k):\n",
    "    \"\"\"Compute nearest neighbors for each point in the given set using sklearn's NearestNeighbors\n",
    "    :parameter\n",
    "    x : ndarray, shape (n_samples, )\n",
    "        Set of points\n",
    "    k : int,\n",
    "        Number of nearest neighbors to search for each point\n",
    "    :returns\n",
    "    d : ndarray, shape (n_samples, n_neighbors)\n",
    "        Distances between the point and each neighbor for each point\n",
    "    \"\"\"\n",
    "    nn = NearestNeighbors(n_neighbors=k+1)\n",
    "    nn.fit(x)\n",
    "    d, i = nn.kneighbors(x)\n",
    "    return d\n",
    "\n",
    "\n",
    "def binary_search(arr, value):\n",
    "    \"\"\"Binary search to find the insertion index in a sorted array\"\"\"\n",
    "    low, high = 0, len(arr)\n",
    "    while low < high:\n",
    "        mid = (low + high) // 2\n",
    "        if arr[mid] < value:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "    return low\n",
    "\n",
    "\n",
    "def mu_approximate(c, d, n_neighbors):\n",
    "    \"\"\"Mutual information calculation based on approximate nearest neighbors\n",
    "    :parameter\n",
    "    c : ndarray, shape (n_samples,)\n",
    "        Samples of a continuous random variable.\n",
    "    d : ndarray, shape (n_samples,)\n",
    "        Samples of a discrete random variable.\n",
    "    n_neighbors : int\n",
    "        Number of nearest neighbors to search for each point\n",
    "    :returns\n",
    "    mi : float\n",
    "        Estimated mutual information. If it turned out to be negative it is\n",
    "        replaced by 0.\n",
    "    Notes\n",
    "    -----\n",
    "    True mutual information can't be negative. If its estimate by a numerical\n",
    "    method is negative, it means (providing the method is adequate) that the\n",
    "    mutual information is close to 0 and replacing it by 0 is a reasonable\n",
    "    strategy.\n",
    "    \"\"\"\n",
    "    n_samples = c.shape[0]\n",
    "    radius = np.empty(n_samples)\n",
    "    label_counts = np.empty(n_samples)\n",
    "    k_all = np.empty(n_samples)\n",
    "\n",
    "    for label in np.unique(d):\n",
    "        mask = (d == label).reshape(-1)\n",
    "        count = np.sum(mask)\n",
    "        if count > n_neighbors + 1:\n",
    "            k = min(n_neighbors, count - 1)\n",
    "            dist = nn_sklearn(c[mask, :], k=k)\n",
    "            radius[mask] = np.nextafter(dist[:, -1], 0)\n",
    "\n",
    "            k_all[mask] = k\n",
    "        label_counts[mask] = count\n",
    "\n",
    "    # Ignore points with unique labels.\n",
    "    mask = label_counts > 1\n",
    "    n_samples = np.sum(mask)\n",
    "    label_counts = label_counts[mask]\n",
    "    k_all = k_all[mask]\n",
    "    c = c[mask]\n",
    "    radius_sklearn = radius[mask]\n",
    "\n",
    "    # Find nearest neighbors (at max 100) using sklearn\n",
    "    D = nn_sklearn(c, k=100)\n",
    "    idc_counts = np.array([max(0, binary_search(D[i], radius_sklearn[i])) for i in range(c.shape[0])])\n",
    "\n",
    "    mi = (digamma(n_samples) + np.mean(digamma(k_all)) -\n",
    "          np.mean(digamma(label_counts)) -\n",
    "          np.mean(digamma(idc_counts + 1)))\n",
    "\n",
    "    # Mutual information cannot be too high. It means that approximation gave bad results.\n",
    "    if mi > 100:\n",
    "        mi = -1\n",
    "    return max(0, mi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43e0faf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Mutual Information I(D; C): 0.7523\n",
      "Estimated Mutual Information I(D; C): 0.5042\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2.38580314 2.94155572 3.5605155  2.31799933 2.31801094 3.60024286\n 3.02622907 2.15160224 2.86721865 2.15588497 2.1542501  2.65466393\n 1.13067733 1.26386967 2.08597344 1.76739101 2.70577718 1.84150078\n 1.48492124 3.51994095 2.32392281 2.53132042 1.47612166 2.09863405\n 2.56200488 1.6696954  2.74922938 2.05885507 2.27731214 2.05809994\n 3.79332923 2.47402679 1.73565619 3.06519785 1.62030394 2.63125963\n 1.09787473 1.5444014  2.62277268 3.00574549 2.60474644 2.40179508\n 2.2706583  1.43809784 1.97456404 2.15784997 3.23106906 2.72654559\n 1.23691312 2.71273274 2.21127647 2.00491463 2.91609122 3.21259752\n 3.14208525 1.89015436 2.2649246  2.71780938 3.17338534 2.14474341\n 2.35229004 1.7012738  1.63772495 3.05811328 3.44257729 2.43265192\n 3.19317568 2.73928605 2.02740221 2.73911605 3.57112685 2.45823793\n 3.5899409  0.63113124 3.0647436  2.54512234 2.27214064 2.54845543\n 1.07814731 2.32823928 2.73608749 3.52859967 2.11709838 1.91187946\n 2.12877496 3.13085781 2.7160329  2.10897373 2.84650565 2.55221496\n 3.16850621 1.98714426 2.25187864 2.20630843 1.44870942 2.69295942\n 2.66816472 2.48718652 2.31769261 1.48275252].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m mi, V \u001b[38;5;241m=\u001b[39m discrete_continuous_info_2(d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), c, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, base\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39me)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated Mutual Information I(D; C): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m mi, V \u001b[38;5;241m=\u001b[39m \u001b[43mmu_approximate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated Mutual Information I(D; C): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --- Step 3: Optional - Visualize data ---\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 98\u001b[0m, in \u001b[0;36mmu_approximate\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m n_neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     97\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_neighbors, count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mnn_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     radius[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnextafter(dist[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    101\u001b[0m     k_all[mask] \u001b[38;5;241m=\u001b[39m k\n",
      "Cell \u001b[0;32mIn[61], line 51\u001b[0m, in \u001b[0;36mnn_sklearn\u001b[0;34m(x, k)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute nearest neighbors for each point in the given set using sklearn's NearestNeighbors\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m:parameter\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mx : ndarray, shape (n_samples, )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Distances between the point and each neighbor for each point\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m nn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m d, i \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mkneighbors(x)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/neighbors/_unsupervised.py:179\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/neighbors/_base.py:526\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 526\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1092\u001b[0m             )\n\u001b[0;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2.38580314 2.94155572 3.5605155  2.31799933 2.31801094 3.60024286\n 3.02622907 2.15160224 2.86721865 2.15588497 2.1542501  2.65466393\n 1.13067733 1.26386967 2.08597344 1.76739101 2.70577718 1.84150078\n 1.48492124 3.51994095 2.32392281 2.53132042 1.47612166 2.09863405\n 2.56200488 1.6696954  2.74922938 2.05885507 2.27731214 2.05809994\n 3.79332923 2.47402679 1.73565619 3.06519785 1.62030394 2.63125963\n 1.09787473 1.5444014  2.62277268 3.00574549 2.60474644 2.40179508\n 2.2706583  1.43809784 1.97456404 2.15784997 3.23106906 2.72654559\n 1.23691312 2.71273274 2.21127647 2.00491463 2.91609122 3.21259752\n 3.14208525 1.89015436 2.2649246  2.71780938 3.17338534 2.14474341\n 2.35229004 1.7012738  1.63772495 3.05811328 3.44257729 2.43265192\n 3.19317568 2.73928605 2.02740221 2.73911605 3.57112685 2.45823793\n 3.5899409  0.63113124 3.0647436  2.54512234 2.27214064 2.54845543\n 1.07814731 2.32823928 2.73608749 3.52859967 2.11709838 1.91187946\n 2.12877496 3.13085781 2.7160329  2.10897373 2.84650565 2.55221496\n 3.16850621 1.98714426 2.25187864 2.20630843 1.44870942 2.69295942\n 2.66816472 2.48718652 2.31769261 1.48275252].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Generate synthetic data ---\n",
    "np.random.seed(42)\n",
    "N = 300  # number of samples\n",
    "dim = 1  # dimensionality of continuous variable\n",
    "\n",
    "# Create 3 discrete classes\n",
    "n_classes = 3\n",
    "samples_per_class = N // n_classes\n",
    "\n",
    "c = []\n",
    "d = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    # Continuous values clustered around different means\n",
    "    mean = np.random.randn(dim) * 5\n",
    "    cov = np.eye(dim) * 0.5\n",
    "    cluster = np.random.multivariate_normal(mean, cov, size=samples_per_class).T\n",
    "    c.append(cluster)\n",
    "    d += [i] * samples_per_class\n",
    "\n",
    "# Stack all continuous samples into a (dim, N) array\n",
    "c = np.hstack(c)\n",
    "d = np.array(d).reshape(1, -1)\n",
    "\n",
    "# --- Step 2: Estimate mutual information ---\n",
    "mi, V = discrete_continuous_info(d, c, k=3, base=np.e)\n",
    "print(f\"Estimated Mutual Information I(D; C): {mi:.4f}\")\n",
    "mi, V = discrete_continuous_info_2(d.reshape(-1), c, k=3, base=np.e)\n",
    "print(f\"Estimated Mutual Information I(D; C): {mi:.4f}\")\n",
    "mi, V = mu_approximate(c.reshape(-1), d.reshape(-1), 3)\n",
    "print(f\"Estimated Mutual Information I(D; C): {mi:.4f}\")\n",
    "\n",
    "# --- Step 3: Optional - Visualize data ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i in range(n_classes):\n",
    "    class_data = c[:, d.flatten() == i]\n",
    "    plt.scatter(class_data[0], class_data[1], label=f'Class {i}', alpha=0.7, color=colors[i])\n",
    "plt.title(\"Synthetic 2D Continuous Data by Class\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac1e662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 64, 64) (100,)\n",
      "[False False False False False False False False False False False False\n",
      "  True  True False False False False  True False False False  True False\n",
      " False False False False False False False  True False False False False\n",
      " False  True  True False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False  True False False  True False False  True False\n",
      " False  True False False False False False False False  True False False\n",
      " False  True False  True False False False False  True False False False\n",
      "  True False  True False]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. NearestNeighbors expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, batch_size)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(c\u001b[38;5;241m.\u001b[39mshape, d\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmu_approximate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[52], line 99\u001b[0m, in \u001b[0;36mmu_approximate\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m     97\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_neighbors, count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask)\n\u001b[0;32m---> 99\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mnn_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m radius[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnextafter(dist[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    102\u001b[0m k_all[mask] \u001b[38;5;241m=\u001b[39m k\n",
      "Cell \u001b[0;32mIn[52], line 51\u001b[0m, in \u001b[0;36mnn_sklearn\u001b[0;34m(x, k)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute nearest neighbors for each point in the given set using sklearn's NearestNeighbors\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m:parameter\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mx : ndarray, shape (n_samples, )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Distances between the point and each neighbor for each point\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m nn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m d, i \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mkneighbors(x)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/neighbors/_unsupervised.py:179\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/neighbors/_base.py:526\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 526\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Desktop/Dev/MADRL-PhD-Thesis-Code/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1101\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m   1107\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1108\u001b[0m         array,\n\u001b[1;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1112\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. NearestNeighbors expected <= 2."
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "c = np.repeat(np.random.rand(int(batch_size / 10), 10, 64, 64).astype(np.float32), 10, axis=0)\n",
    "d = np.random.randint(0, 5, batch_size)\n",
    "\n",
    "print(c.shape, d.shape)\n",
    "print(mu_approximate(c, d, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2092fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import psi\n",
    "\n",
    "\n",
    "def findpt(c_sorted, target):\n",
    "    \"\"\"\n",
    "    Find the \"index\" of where `target` would go in sorted array `c_sorted`.\n",
    "    This mimics MATLAB's 0.5 behavior between indices.\n",
    "    \"\"\"\n",
    "    if target < c_sorted[0]:\n",
    "        return 0.5\n",
    "    elif target > c_sorted[-1]:\n",
    "        return len(c_sorted) + 0.5\n",
    "    else:\n",
    "        return np.searchsorted(c_sorted, target, side='left')\n",
    "\n",
    "\n",
    "def discrete_continuous_info_fast(d, c, k=3, base=np.e):\n",
    "    d = np.asarray(d).flatten()\n",
    "    c = np.asarray(c).flatten()\n",
    "    \n",
    "    assert len(d) == len(c), \"d and c must be the same length\"\n",
    "\n",
    "    # Sort c and reorder d accordingly\n",
    "    idx = np.argsort(c)\n",
    "    c = c[idx]\n",
    "    d = d[idx]\n",
    "\n",
    "    # Bin the continuous data by discrete labels\n",
    "    unique_labels, symbol_IDs = np.unique(d, return_inverse=True)\n",
    "    num_d_symbols = len(unique_labels)\n",
    "\n",
    "    c_split = [[] for _ in range(num_d_symbols)]\n",
    "    cs_indices = [[] for _ in range(num_d_symbols)]\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        label_id = symbol_IDs[i]\n",
    "        c_split[label_id].append(c[i])\n",
    "        cs_indices[label_id].append(i)\n",
    "\n",
    "    c_split = [np.array(cs) for cs in c_split]\n",
    "    V = np.zeros(len(d))\n",
    "    m_tot = 0\n",
    "    av_psi_Nd = 0\n",
    "    psi_ks = 0\n",
    "\n",
    "    for c_bin in range(num_d_symbols):\n",
    "        bin_c = c_split[c_bin]\n",
    "        indices = cs_indices[c_bin]\n",
    "        bin_len = len(bin_c)\n",
    "        one_k = min(k, bin_len - 1)\n",
    "\n",
    "        if one_k > 0:\n",
    "            for pivot in range(bin_len):\n",
    "                one_c = bin_c[pivot]\n",
    "                left = pivot\n",
    "                right = pivot\n",
    "\n",
    "                # Find the k-th nearest neighbor (1D)\n",
    "                for _ in range(one_k):\n",
    "                    if left == 0:\n",
    "                        right += 1\n",
    "                    elif right == bin_len - 1:\n",
    "                        left -= 1\n",
    "                    else:\n",
    "                        if abs(bin_c[left - 1] - one_c) < abs(bin_c[right + 1] - one_c):\n",
    "                            left -= 1\n",
    "                        else:\n",
    "                            right += 1\n",
    "\n",
    "                # Radius of neighborhood\n",
    "                distance_to_neighbor = abs(bin_c[right] - one_c) if right > pivot else abs(bin_c[left] - one_c)\n",
    "\n",
    "                # Count number of total samples in full c within the same radius\n",
    "                if right > pivot:\n",
    "                    m = int(np.floor(findpt(c, bin_c[right]) - findpt(c, one_c - distance_to_neighbor)))\n",
    "                else:\n",
    "                    m = int(np.floor(findpt(c, one_c + distance_to_neighbor) - findpt(c, bin_c[left])))\n",
    "\n",
    "                if m < one_k:\n",
    "                    m = one_k\n",
    "\n",
    "                m_tot += psi(m)\n",
    "                V[indices[pivot]] = 2 * distance_to_neighbor\n",
    "        else:\n",
    "            m_tot += psi(num_d_symbols * 2)\n",
    "            V[indices[0]] = 2 * (c[-1] - c[0])\n",
    "\n",
    "        p_d = bin_len / len(d)\n",
    "        av_psi_Nd += p_d * psi(p_d * len(d))\n",
    "        psi_ks += p_d * psi(max(one_k, 1))\n",
    "\n",
    "    f = (psi(len(d)) - av_psi_Nd + psi_ks - m_tot / len(d)) / np.log(base)\n",
    "    return f, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aed56d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MI (fast version): 0.4344\n"
     ]
    }
   ],
   "source": [
    "# Example with synthetic data\n",
    "np.random.seed(1)\n",
    "N = 300\n",
    "d = np.random.choice([0, 1, 2], size=N)\n",
    "c = np.random.randn(N) + d  # continuous variable depends on discrete label\n",
    "\n",
    "mi, V = discrete_continuous_info_fast(d, c)\n",
    "print(f\"Estimated MI (fast version): {mi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521007b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
